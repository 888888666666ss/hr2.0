// AI æœåŠ¡é…ç½®å’Œæ¥å£
export interface AIConfig {
  apiKey: string
  apiUrl: string
  model: string
}

export interface AIMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

export interface AIResponse {
  content: string
  usage?: {
    total_tokens: number
    prompt_tokens: number
    completion_tokens: number
  }
}

// æ™ºè°± GLM AI æœåŠ¡
export class GLMAIService {
  private config: AIConfig

  constructor() {
    this.config = {
      apiKey: process.env.GLM_API_KEY || '',
      apiUrl: process.env.GLM_API_URL || 'https://open.bigmodel.cn/api/paas/v4/chat/completions',
      model: 'glm-4-plus' // æˆ–è€…ä½¿ç”¨å…¶ä»–æ¨¡å‹
    }

    // åœ¨å¼€å‘/æ„å»ºæ¨¡å¼ä¸‹ï¼Œå¦‚æœæ²¡æœ‰API keyï¼Œåªè­¦å‘Šè€Œä¸æŠ›é”™
    if (!this.config.apiKey) {
      console.warn('âš ï¸ GLM API key not configured. AI features will use mock responses.')
    }
  }

  async chat(messages: AIMessage[]): Promise<AIResponse> {
    // å¦‚æœæ²¡æœ‰é…ç½® API keyï¼Œè¿”å›æ¨¡æ‹Ÿå“åº”
    if (!this.config.apiKey) {
      console.warn('ğŸ¤– Using mock AI response (API key not configured)')
      return {
        content: JSON.stringify({
          matchScore: 75,
          strengths: ['ç›¸å…³å·¥ä½œç»éªŒ', 'æŠ€èƒ½åŒ¹é…'],
          concerns: ['éœ€è¦è¿›ä¸€æ­¥è¯„ä¼°'],
          skills: ['JavaScript', 'React', 'Node.js'],
          recommendations: ['å»ºè®®è¿›å…¥é¢è¯•æµç¨‹']
        }),
        usage: {
          total_tokens: 100,
          prompt_tokens: 80,
          completion_tokens: 20
        }
      }
    }

    try {
      const response = await fetch(this.config.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.config.apiKey}`
        },
        body: JSON.stringify({
          model: this.config.model,
          messages,
          temperature: 0.7,
          max_tokens: 2000,
          stream: false
        })
      })

      if (!response.ok) {
        const error = await response.text()
        throw new Error(`GLM API error: ${response.status} - ${error}`)
      }

      const data = await response.json()
      
      return {
        content: data.choices[0]?.message?.content || '',
        usage: data.usage
      }
    } catch (error) {
      console.error('GLM AI Service Error:', error)
      throw error
    }
  }

  // ç®€å†åˆ†æä¸“ç”¨æ–¹æ³•
  async analyzeResume(resumeText: string, jobDescription: string): Promise<{
    matchScore: number
    strengths: string[]
    concerns: string[]
    skills: string[]
    recommendations: string[]
  }> {
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„HRæ‹›è˜åŠ©æ‰‹ã€‚è¯·åˆ†æå€™é€‰äººç®€å†ä¸èŒä½è¦æ±‚çš„åŒ¹é…åº¦ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{
  "matchScore": 85,
  "strengths": ["æŠ€èƒ½åŒ¹é…åº¦é«˜", "å·¥ä½œç»éªŒä¸°å¯Œ"],
  "concerns": ["ç¼ºå°‘æŸäº›å…³é”®æŠ€èƒ½"],
  "skills": ["JavaScript", "React", "Node.js"],
  "recommendations": ["å»ºè®®è¿›å…¥é¢è¯•æµç¨‹", "å¯ä»¥è€ƒè™‘æŠ€æœ¯é¢è¯•"]
}

åŒ¹é…åˆ†æ•°èŒƒå›´ï¼š0-100åˆ†`

    const userPrompt = `èŒä½æè¿°ï¼š
${jobDescription}

å€™é€‰äººç®€å†ï¼š
${resumeText}

è¯·åˆ†æè¿™ä»½ç®€å†ä¸èŒä½çš„åŒ¹é…åº¦ï¼Œå¹¶ç»™å‡ºè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šã€‚`

    const response = await this.chat([
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt }
    ])

    try {
      // å°è¯•è§£æJSONå“åº”
      const analysis = JSON.parse(response.content)
      return analysis
    } catch (error) {
      // å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æ„
      console.error('Failed to parse AI response:', error)
      return {
        matchScore: 50,
        strengths: ['å¾…è¯„ä¼°'],
        concerns: ['AIåˆ†æè§£æå¤±è´¥'],
        skills: [],
        recommendations: ['å»ºè®®äººå·¥å®¡æ ¸']
      }
    }
  }

  // ç”Ÿæˆé¢è¯•é—®é¢˜
  async generateInterviewQuestions(
    position: string, 
    level: string, 
    skills: string[]
  ): Promise<{
    technical: string[]
    behavioral: string[]
    situational: string[]
  }> {
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„HRé¢è¯•å®˜ã€‚è¯·æ ¹æ®èŒä½ä¿¡æ¯ç”Ÿæˆé¢è¯•é—®é¢˜ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{
  "technical": ["æŠ€æœ¯ç›¸å…³é—®é¢˜1", "æŠ€æœ¯ç›¸å…³é—®é¢˜2"],
  "behavioral": ["è¡Œä¸ºé¢è¯•é—®é¢˜1", "è¡Œä¸ºé¢è¯•é—®é¢˜2"],
  "situational": ["æƒ…æ™¯é¢è¯•é—®é¢˜1", "æƒ…æ™¯é¢è¯•é—®é¢˜2"]
}

æ¯ä¸ªç±»åˆ«ç”Ÿæˆ3-5ä¸ªé—®é¢˜ã€‚`

    const userPrompt = `èŒä½ï¼š${position}
çº§åˆ«ï¼š${level}
æŠ€èƒ½è¦æ±‚ï¼š${skills.join(', ')}

è¯·ç”Ÿæˆé€‚åˆè¿™ä¸ªèŒä½çš„é¢è¯•é—®é¢˜ã€‚`

    const response = await this.chat([
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt }
    ])

    try {
      return JSON.parse(response.content)
    } catch (error) {
      console.error('Failed to parse interview questions:', error)
      return {
        technical: ['è¯·ä»‹ç»ä½ çš„æŠ€æœ¯èƒŒæ™¯'],
        behavioral: ['è¯·æè¿°ä¸€æ¬¡ä½ è§£å†³å¤æ‚é—®é¢˜çš„ç»å†'],
        situational: ['å¦‚æœé‡åˆ°æŠ€æœ¯éš¾é¢˜ï¼Œä½ ä¼šå¦‚ä½•å¤„ç†ï¼Ÿ']
      }
    }
  }

  // é¢è¯•è¯„ä¼°
  async evaluateInterview(
    questions: string[],
    answers: string[],
    position: string
  ): Promise<{
    overallScore: number
    technicalScore: number
    communicationScore: number
    cultureScore: number
    feedback: string[]
    recommendation: 'hire' | 'no_hire' | 'maybe'
  }> {
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢è¯•è¯„ä¼°ä¸“å®¶ã€‚è¯·æ ¹æ®é¢è¯•é—®ç­”å¯¹å€™é€‰äººè¿›è¡Œè¯„ä¼°ã€‚

è¯„åˆ†æ ‡å‡†ï¼š
- æ•´ä½“è¯„åˆ†ï¼š0-100åˆ†
- æŠ€æœ¯èƒ½åŠ›ï¼š0-100åˆ†  
- æ²Ÿé€šèƒ½åŠ›ï¼š0-100åˆ†
- æ–‡åŒ–åŒ¹é…ï¼š0-100åˆ†

æ¨èç»“æœï¼šhireï¼ˆæ¨èå½•ç”¨ï¼‰ã€no_hireï¼ˆä¸æ¨èï¼‰ã€maybeï¼ˆéœ€è¦è¿›ä¸€æ­¥è¯„ä¼°ï¼‰

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{
  "overallScore": 85,
  "technicalScore": 90,
  "communicationScore": 80,
  "cultureScore": 85,
  "feedback": ["æŠ€æœ¯èƒ½åŠ›å¼º", "æ²Ÿé€šæ¸…æ™°"],
  "recommendation": "hire"
}`

    const qaText = questions.map((q, i) => `
é—®é¢˜ï¼š${q}
å›ç­”ï¼š${answers[i] || 'æœªå›ç­”'}
`).join('\n')

    const userPrompt = `èŒä½ï¼š${position}

é¢è¯•é—®ç­”ï¼š
${qaText}

è¯·å¯¹è¿™æ¬¡é¢è¯•è¿›è¡Œè¯„ä¼°ã€‚`

    const response = await this.chat([
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt }
    ])

    try {
      return JSON.parse(response.content)
    } catch (error) {
      console.error('Failed to parse interview evaluation:', error)
      return {
        overallScore: 70,
        technicalScore: 70,
        communicationScore: 70,
        cultureScore: 70,
        feedback: ['è¯„ä¼°è§£æå¤±è´¥ï¼Œå»ºè®®äººå·¥å®¡æ ¸'],
        recommendation: 'maybe'
      }
    }
  }
}

// å¯¼å‡ºAIæœåŠ¡å®ä¾‹
export const aiService = new GLMAIService()